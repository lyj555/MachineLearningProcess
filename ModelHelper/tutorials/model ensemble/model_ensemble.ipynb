{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble\n",
    "\n",
    "本部分主要分为三块，分别是Stacking，Blending和Bagging。这几部分所有实现均包含了单机版本和分布式版本，下面的介绍中主要从这两方面介绍。\n",
    "\n",
    "## 1. Stacking\n",
    "\n",
    "Stacking模型是指将多种分类器组合在一起来取得更好表现的一种集成学习模型。一般情况下，Stacking模型分为两层。第一层中我们训练多个不同的模型，然后再以第一层训练的各个模型的输出作为输入来训练第二层的模型，以得到一个最终的输出。可参考[文章](https://blog.csdn.net/data_scientist/article/details/78900265)\n",
    "> 在实现上，Stacking方式主要分为StackingClassifier和StackingRegressor，两者参数完全一致，下面的介绍中仅以StackingClassifier为例\n",
    "\n",
    "### 1.1 单机版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:25:39.819850Z",
     "start_time": "2019-12-04T03:25:39.045320Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,\\\n",
    "    RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "from model_helper.model_ensemble import StackingClassifier, StackingRegressor, \\\n",
    "BlendingClassifier, BlendingRegressor, BaggingClassifier, BaggingRegressor\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:25:42.340568Z",
     "start_time": "2019-12-04T03:25:42.291652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape (5000, 20)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=20, n_classes=2, random_state=234)\n",
    "\n",
    "print(\"X's shape\", X.shape)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法1\n",
    "最简单使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:25:50.996150Z",
     "start_time": "2019-12-04T03:25:47.254096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3(base learner model number) × 5(fold num) = 15 models.\n",
      "1/15(model_index:0, fold_index:0) starts\n",
      "2/15(model_index:0, fold_index:1) starts\n",
      "3/15(model_index:0, fold_index:2) starts\n",
      "4/15(model_index:0, fold_index:3) starts\n",
      "5/15(model_index:0, fold_index:4) starts\n",
      "6/15(model_index:1, fold_index:0) starts\n",
      "7/15(model_index:1, fold_index:1) starts\n",
      "8/15(model_index:1, fold_index:2) starts\n",
      "9/15(model_index:1, fold_index:3) starts\n",
      "10/15(model_index:1, fold_index:4) starts\n",
      "11/15(model_index:2, fold_index:0) starts\n",
      "12/15(model_index:2, fold_index:1) starts\n",
      "13/15(model_index:2, fold_index:2) starts\n",
      "14/15(model_index:2, fold_index:3) starts\n",
      "15/15(model_index:2, fold_index:4) starts\n",
      "[1]. train base learner done, cost 3 seconds.\n",
      "[2]. get base learner prediction...\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [0, 1, 2].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.9825956598515821\n"
     ]
    }
   ],
   "source": [
    "clf = StackingClassifier(k_fold=5, base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression())\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法2\n",
    "\n",
    "可以通过交叉验证的效果来从给定的基学习器中进行选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:25:58.923311Z",
     "start_time": "2019-12-04T03:25:54.358918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3(base learner model number) × 5(fold num) = 15 models.\n",
      "1/15(model_index:0, fold_index:0) starts\n",
      "2/15(model_index:0, fold_index:1) starts\n",
      "3/15(model_index:0, fold_index:2) starts\n",
      "4/15(model_index:0, fold_index:3) starts\n",
      "5/15(model_index:0, fold_index:4) starts\n",
      "6/15(model_index:1, fold_index:0) starts\n",
      "7/15(model_index:1, fold_index:1) starts\n",
      "8/15(model_index:1, fold_index:2) starts\n",
      "9/15(model_index:1, fold_index:3) starts\n",
      "10/15(model_index:1, fold_index:4) starts\n",
      "11/15(model_index:2, fold_index:0) starts\n",
      "12/15(model_index:2, fold_index:1) starts\n",
      "13/15(model_index:2, fold_index:2) starts\n",
      "14/15(model_index:2, fold_index:3) starts\n",
      "15/15(model_index:2, fold_index:4) starts\n",
      "[1]. train base learner done, cost 4 seconds.\n",
      "[2]. get base learner prediction...\n",
      "average 5 fold metric of every model is [0.9689914937102717, 0.97972802594318, 0.9057468225768597]\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [1 0].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.9827894958663137\n"
     ]
    }
   ],
   "source": [
    "def selector(model_metrics):\n",
    "    model_avg_metric = np.array(list(map(lambda x: sum(x) / len(x), model_metrics)))\n",
    "    return model_avg_metric.argsort()[-2:][::-1]  # get top 2 best model\n",
    "\n",
    "clf = StackingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression(), metric_func=roc_auc_score, select_base_learner=selector)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法3\n",
    "可以指定每个基学习器的使用随机采样的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:05.839909Z",
     "start_time": "2019-12-04T03:26:02.455478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3(base learner model number) × 5(fold num) = 15 models.\n",
      "1/15(model_index:0, fold_index:0) starts\n",
      "2/15(model_index:0, fold_index:1) starts\n",
      "3/15(model_index:0, fold_index:2) starts\n",
      "4/15(model_index:0, fold_index:3) starts\n",
      "5/15(model_index:0, fold_index:4) starts\n",
      "6/15(model_index:1, fold_index:0) starts\n",
      "7/15(model_index:1, fold_index:1) starts\n",
      "8/15(model_index:1, fold_index:2) starts\n",
      "9/15(model_index:1, fold_index:3) starts\n",
      "10/15(model_index:1, fold_index:4) starts\n",
      "11/15(model_index:2, fold_index:0) starts\n",
      "12/15(model_index:2, fold_index:1) starts\n",
      "13/15(model_index:2, fold_index:2) starts\n",
      "14/15(model_index:2, fold_index:3) starts\n",
      "15/15(model_index:2, fold_index:4) starts\n",
      "[1]. train base learner done, cost 3 seconds.\n",
      "[2]. get base learner prediction...\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [0, 1, 2].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.9821475252120192\n"
     ]
    }
   ],
   "source": [
    "clf = StackingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression(),\n",
    "                         feature_fraction=0.8)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法4\n",
    "\n",
    "单机版可以指定多进程的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:12.870809Z",
     "start_time": "2019-12-04T03:26:10.504214Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3(base learner model number) × 5(fold num) = 15 models.\n",
      "1/15(model_index:0, fold_index:0) starts\n",
      "2/15(model_index:0, fold_index:1) starts\n",
      "3/15(model_index:0, fold_index:2) starts\n",
      "4/15(model_index:0, fold_index:3) starts\n",
      "5/15(model_index:0, fold_index:4) starts\n",
      "6/15(model_index:1, fold_index:0) starts\n",
      "7/15(model_index:1, fold_index:1) starts\n",
      "8/15(model_index:1, fold_index:2) starts\n",
      "9/15(model_index:1, fold_index:3) starts\n",
      "10/15(model_index:1, fold_index:4) starts\n",
      "11/15(model_index:2, fold_index:0) starts\n",
      "12/15(model_index:2, fold_index:1) starts\n",
      "13/15(model_index:2, fold_index:2) starts\n",
      "14/15(model_index:2, fold_index:3) starts\n",
      "15/15(model_index:2, fold_index:4) starts\n",
      "[1]. train base learner done, cost 2 seconds.\n",
      "[2]. get base learner prediction...\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [0, 1, 2].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.982207987822119\n"
     ]
    }
   ],
   "source": [
    "clf = StackingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression(),\n",
    "                         feature_fraction=0.8, enable_multiprocess=True, n_jobs=2)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法5\n",
    "\n",
    "因为基学习器是根据k-fold样式来生成特征，所以在生成k-fold数据时可以指定按列进行分层采样，具体使用如下，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:19.189186Z",
     "start_time": "2019-12-04T03:26:15.911483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3(base learner model number) × 5(fold num) = 15 models.\n",
      "1/15(model_index:0, fold_index:0) starts\n",
      "2/15(model_index:0, fold_index:1) starts\n",
      "3/15(model_index:0, fold_index:2) starts\n",
      "4/15(model_index:0, fold_index:3) starts\n",
      "5/15(model_index:0, fold_index:4) starts\n",
      "6/15(model_index:1, fold_index:0) starts\n",
      "7/15(model_index:1, fold_index:1) starts\n",
      "8/15(model_index:1, fold_index:2) starts\n",
      "9/15(model_index:1, fold_index:3) starts\n",
      "10/15(model_index:1, fold_index:4) starts\n",
      "11/15(model_index:2, fold_index:0) starts\n",
      "12/15(model_index:2, fold_index:1) starts\n",
      "13/15(model_index:2, fold_index:2) starts\n",
      "14/15(model_index:2, fold_index:3) starts\n",
      "15/15(model_index:2, fold_index:4) starts\n",
      "[1]. train base learner done, cost 3 seconds.\n",
      "[2]. get base learner prediction...\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [0, 1, 2].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.9819856988143992\n"
     ]
    }
   ],
   "source": [
    "clf = StackingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression(),\n",
    "                         feature_fraction=0.8)\n",
    "\n",
    "clf.fit(X=train_x, y=train_y, stratify=True, stratify_col=train_y)\n",
    "\n",
    "pred = clf.predict_proba(test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 分布式版本\n",
    "\n",
    "在分布式版本中，使用方式和单机版本一致，不同之处是分布式版本中需要额外指定两个参数，`spark`和`distribute`，下面仅列举一个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"distribute\").enableHiveSupport().getOrCreate()  # 需要创建spark连接\n",
    "\n",
    "\n",
    "clf = StackingClassifier(k_fold=5, base_learner_list=[RandomForestClassifier(), \n",
    "                                                      GradientBoostingClassifier(),\n",
    "                                                      DecisionTreeClassifier()], \n",
    "                         meta_learner=LogisticRegression(), \n",
    "                         distribute=True, spark=spark)  # 相比单机版，需要额外指定此两个参数\n",
    "clf.fit(X=train_x, y=train_y)  # 训练\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]  # 预测\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)  # 评估\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Blending\n",
    "\n",
    "Blending与Stacking大致相同，只是Blending的主要区别在于训练集不是通过k-fold的CV策略来获得预测值从而生成第二阶段模型的特征，而是建立一个Holdout集，例如10%的训练数据。\n",
    "\n",
    "从使用参数来看，和Stacking的唯一不同之处即是，参数由`k_fold`变为`base_train_size`(指定训练部分数据的比例)，下面仅介绍一个例子，其余使用方式和Stacking部分完全一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:26.160387Z",
     "start_time": "2019-12-04T03:26:25.462195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "base learner used sample num is 2800, fraction is 0.8\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "[2]. get base learner prediction...\n",
      "model's test set metric is [0.9647576732045398, 0.9819901645514725, 0.9019605436499167].\n",
      "meta learner used sample num is 700, fraction is 0.2\n",
      "[2]. get base learner prediction done, cost 0 seconds.\n",
      "[3]. train meta learner...\n",
      "last used model index is [1 0].\n",
      "[3]. train meta learner done, cost 0 seconds.\n",
      "0.9822897901769598\n"
     ]
    }
   ],
   "source": [
    "def selector(model_metrics):\n",
    "    model_avg_metric = np.array(model_metrics)\n",
    "    return model_avg_metric.argsort()[-2:][::-1]  # 选择得分最高的两个模型\n",
    "\n",
    "clf = BlendingClassifier(base_train_size=0.8,\n",
    "                         base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                            DecisionTreeClassifier()],\n",
    "                         meta_learner=LogisticRegression(), metric_func=roc_auc_score, select_base_learner=selector,\n",
    "                         feature_fraction=0.8)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bagging\n",
    "\n",
    "Bagging同样是属于模型集成的一种方式，不同于Stacking和Blending的两阶段训练，Bagging只需要一阶段的训练，然后将一阶段的模型预测结果集成即可。\n",
    "\n",
    "### 3.1 单机版本\n",
    "\n",
    "#### 方法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:31.251269Z",
     "start_time": "2019-12-04T03:26:30.285801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "train done.\n",
      "0.9795538570699464\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()])\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T01:40:43.583694Z",
     "start_time": "2019-12-04T01:40:43.327148Z"
    }
   },
   "source": [
    "#### 方法2\n",
    "添加特征随机选取和boostrap采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:37.560591Z",
     "start_time": "2019-12-04T03:26:36.783887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "train done.\n",
      "0.9774732319576904\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()],\n",
    "                        feature_fraction=0.8, bootstrap=True)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法3\n",
    "\n",
    "上面的方法产生的预测值都是通过平均得到的，多数情况下上面两种够用，如果想为每个基学习器加一个权重，可以预先通过数据集训练得到每个基学习器的评估指标，然后通过自定义的方式将指标转换为权重，从而得到加权预测值，下面着重介绍这一大类的方式。\n",
    "\n",
    "下面是通过5折交叉验证的平均auc值得到每个基学习器的指标，然后通过softmax归一转换为权重，从而实现加权预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:45.168994Z",
     "start_time": "2019-12-04T03:26:40.857667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "[2]. get metric...\n",
      "[2]. get metric done, cost 3.\n",
      "train done.\n",
      "0.9750111589081875\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()],\n",
    "                        feature_fraction=0.8, bootstrap=True,\n",
    "                        get_model_metric=True, metric_to_weight=\"softmax\", metric_func=roc_auc_score, metric_k_fold=5,\n",
    "                        predict_strategy=\"weight\")\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法4\n",
    "\n",
    "这个方法和方法3一致，不同的是通过验证集的方式得到评估指标。\n",
    "将输入数据的70%作为训练集，其余百分之30%作为测试集，通过30%的验证集的auc值作为评估指标，然后通过softmax的方式将评估指标转换为权重（概率分布）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:49.894772Z",
     "start_time": "2019-12-04T03:26:48.515685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "[2]. get metric...\n",
      "[2]. get metric done, cost 0.\n",
      "train done.\n",
      "0.9785571131593315\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()],\n",
    "                        feature_fraction=0.8, bootstrap=False,\n",
    "                        get_model_metric=True, metric_func=roc_auc_score, metric_base_train_size=0.7,\n",
    "                        metric_to_weight=\"softmax\", predict_strategy=\"weight\")\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法5\n",
    "\n",
    "下面这种方式可以自定义指标到权重的变换方式，其中`metric_sample_size`指预先从全量数据中取出该比例的数据，仅通过这部分数据进行指标的评估，往往在数据量大时，这种方式可以显著的减少训练时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:26:57.222146Z",
     "start_time": "2019-12-04T03:26:56.039360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "[2]. get metric...\n",
      "[2]. get metric done, cost 0.\n",
      "train done.\n",
      "0.9805123672712335\n"
     ]
    }
   ],
   "source": [
    "def metric_to_weight(metrics):\n",
    "    model_weight = np.array(metrics)\n",
    "    model_weight = model_weight / sum(model_weight)\n",
    "    return model_weight\n",
    "\n",
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()],\n",
    "                        feature_fraction=0.8, bootstrap=False, sample_fraction=0.9,\n",
    "                        get_model_metric=True, metric_sample_size=0.8,\n",
    "                        metric_func=roc_auc_score, metric_base_train_size=0.7,\n",
    "                        metric_to_weight=metric_to_weight,\n",
    "                        predict_strategy=\"weight\", random_state=222)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法6\n",
    "\n",
    "单机版中支持多进程的方式，需要指定两个参数，`enable_multiprocess`和`n_jobs`即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T03:27:04.501494Z",
     "start_time": "2019-12-04T03:27:03.394575Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]. train base learner...\n",
      "altogether train 3 models.\n",
      "1/3(model_index:0) starts\n",
      "2/3(model_index:1) starts\n",
      "3/3(model_index:2) starts\n",
      "[1]. train base learner done, cost 0 seconds.\n",
      "[2]. get metric...\n",
      "[2]. get metric done, cost 0.\n",
      "train done.\n",
      "0.9796018714956138\n"
     ]
    }
   ],
   "source": [
    "def metric_to_weight(metrics):\n",
    "    model_weight = np.array(metrics)\n",
    "    model_weight = model_weight / sum(model_weight)\n",
    "    return model_weight\n",
    "\n",
    "clf = BaggingClassifier(base_learner_list=[RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                                           DecisionTreeClassifier()],\n",
    "                        feature_fraction=0.8, bootstrap=False, sample_fraction=0.9,\n",
    "                        get_model_metric=True, metric_sample_size=0.8,\n",
    "                        metric_func=roc_auc_score, metric_base_train_size=0.7,\n",
    "                        metric_to_weight=metric_to_weight,\n",
    "                        predict_strategy=\"weight\", enable_multiprocess=True,\n",
    "                        n_jobs=2, random_state=222)\n",
    "clf.fit(X=train_x, y=train_y)\n",
    "\n",
    "pred = clf.predict_proba(X=test_x)[:, 1]\n",
    "auc_val = roc_auc_score(y_true=test_y, y_score=pred)\n",
    "print(auc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 分布式版本\n",
    "\n",
    "和上面Stacking和Blending的使用方式一致，主要是额外添加两个参数`spark`和`distribute`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
